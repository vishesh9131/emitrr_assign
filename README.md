# Project's mind 

```
Physician Notetaker
â”œâ”€â”€ 1. Medical NLP Summarization
â”‚   â”œâ”€â”€ Named Entity Recognition (NER)
â”‚   â”‚   â””â”€â”€ Extract: Symptoms, Treatment ,Diagnosis, Prognosis
â”‚   â”œâ”€â”€ Text Summarization
â”‚   â”‚   â””â”€â”€ Convert transcript to structured medical report
â”‚   â””â”€â”€ Keyword Extraction
â”‚       â””â”€â”€ Identify important medical phrases
â”‚
â”œâ”€â”€ 2. Sentiment & Intent Analysis
â”‚   â”œâ”€â”€ Sentiment Classification
â”‚   â”‚   â””â”€â”€ Classify patient sentiment (Anxious, Neutral, Reassured)
â”‚   â””â”€â”€ Intent Detection
â”‚       â””â”€â”€ Identify patient intent (seeking reassurance, reporting symptoms, etc.)
â”‚
â”œâ”€â”€ 3. SOAP Note Generation (Bonus)
â”‚   â”œâ”€â”€ Automated SOAP Note Generation
â”‚   â”œâ”€â”€ Logical Mapping of SOAP sections
â”‚   â””â”€â”€ Text Structuring & Formatting
â”‚
â””â”€â”€ Submission Requirements
    â”œâ”€â”€ GitHub Repository
    â”œâ”€â”€ Live Application
    â””â”€â”€ README with setup instructions, screenshots, and methodology
```

```
prasn_1
~1/
â”œâ”€â”€ app.py                # Main Streamlit application
â”œâ”€â”€ requirements.txt      # Dependencies
â”œâ”€â”€ models/               # For storing models
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ ner.py            # Named Entity Recognition
â”‚   â”œâ”€â”€ summarization.py  # Text Summarization
â”‚   â””â”€â”€ keyword.py        # Keyword Extraction
â””â”€â”€ README.md
```


Hereâ€™s an interactive README.md file that includes collapsible sections, tables, and formatted summaries for easy navigation.

â¸»

ğŸ“Š Physician Notetaker - Model Performance Report

ğŸ” Overview

This document provides a detailed comparison of multiple models for Named Entity Recognition (NER) and Medical NLP Tasks, including:
	â€¢	Rule-Based Model
	â€¢	BioBERT Model
	â€¢	BERT_CONLL03 Model
	â€¢	FineTuned_BioBERT Model

Rule-Based Model achieved the highest overall accuracy of 0.1470.

â¸»

ğŸ† Best Performing Model:

Rule-Based Model with an overall accuracy of 0.1470.

<details>
<summary>ğŸ“ˆ Overall Model Accuracy</summary>


Model	Overall Accuracy	Patient Name Accuracy	Symptoms F1	Diagnosis Match	Treatment F1	Status Match	Prognosis Match
Rule-Based	0.1470	0.7527	0.1387	0.0645	0.0339	0.0000	0.0000
BioBERT	0.1014	0.6849	0.0660	0.0323	0.0264	0.0000	0.0000
BERT_CONLL03	0.1175	0.6747	0.0660	0.0323	0.0264	0.0000	0.0000
FineTuned_BioBERT	0.1014	0.5565	0.0660	0.0323	0.0264	0.0000	0.0000

</details>




â¸»

ğŸ… Field-by-Field Comparison

<details>
<summary>ğŸ”¬ Patient Name Accuracy</summary>


Model	Patient Name Accuracy
Rule-Based	0.7527
BioBERT	0.6849
BERT_CONLL03	0.6747
FineTuned_BioBERT	0.5565

Rule-Based model performed best in patient name detection.

</details>


<details>
<summary>ğŸ’‰ Symptoms F1 Score</summary>


Model	Symptoms F1
Rule-Based	0.1387
BioBERT	0.0660
BERT_CONLL03	0.0660
FineTuned_BioBERT	0.0660

Rule-Based model performed best in symptoms extraction.

</details>


<details>
<summary>ğŸ§¾ Diagnosis & Treatment</summary>


Model	Diagnosis Match	Treatment F1
Rule-Based	0.0645	0.0339
BioBERT	0.0323	0.0264
BERT_CONLL03	0.0323	0.0264
FineTuned_BioBERT	0.0323	0.0264

Rule-Based model performed best in extracting Diagnosis and Treatment.

</details>




â¸»

ğŸ“Œ Chunk-Wise Model Comparison

<details>
<summary>ğŸ“Š Click to Expand Model Comparison Table</summary>


Chunk	Rule-Based	BioBERT	FineTuned_BioBERT	BERT_CONLL03	Best Model
CHUNK_A	0.1111	0.0370	0.0370	0.0370	Rule-Based
CHUNK_B	0.4103	0.3846	0.3846	0.3846	Rule-Based
CHUNK_C	0.1667	0.1667	0.1667	0.1667	Tie
CHUNK_D	0.2083	0.2000	0.2000	0.2000	Rule-Based
â€¦	â€¦	â€¦	â€¦	â€¦	â€¦

</details>


ğŸ† Model Performance Summary:
	â€¢	Rule-Based model is best on 26 chunks
	â€¢	BioBERT model is best on 16 chunks
	â€¢	FineTuned_BioBERT model is best on 16 chunks
	â€¢	BERT_CONLL03 model is best on 17 chunks

â¸»

ğŸ¯ Performance on Test Chunks

<details>
<summary>ğŸ“Œ Average Accuracy on Test Chunks</summary>


Model	Avg. Accuracy on Test Chunks
Rule-Based	0.1467
BioBERT	0.0300
BERT_CONLL03	0.0800

Rule-Based model performed best on test data.

</details>


ğŸ“Œ Best Model on Test Chunks

Model	Best on # Test Chunks
Rule-Based	10 (100.0%)
BioBERT	3 (30.0%)
FineTuned_BioBERT	3 (30.0%)
BERT_CONLL03	5 (50.0%)



â¸»

ğŸ”¬ Name Detection Accuracy

<details>
<summary>ğŸ§‘â€âš•ï¸ Name Detection Analysis</summary>


Model	Name Detection Accuracy
Rule-Based	0.7667
BioBERT	0.8667
BERT_CONLL03	0.7333
FineTuned_BioBERT	0.8000

BioBERT performs best in name detection.

</details>




â¸»

ğŸš€ Conclusion
	â€¢	ğŸ† Rule-Based Model performs best overall with the highest accuracy across multiple chunks and test cases.
	â€¢	ğŸ©º BioBERT Model excels in name detection accuracy.
	â€¢	ğŸ“ˆ Further improvements needed in Status Match & Prognosis Match (all models scored 0.0000).

âœ… Next Steps:
ğŸ”¹ Improve Diagnosis & Prognosis matching using fine-tuned models.
ğŸ”¹ Implement hybrid approaches combining rule-based and transformer models for better accuracy.
ğŸ”¹ Enhance test chunk performance with more diverse training data.

â¸»

ğŸ’¡ Want to Explore More?

Run additional evaluations on new datasets to further analyze model performance!

ğŸ“Œ Developed for Physician Notetaker NLP Task | ğŸš€ Optimized for Medical Conversations

â¸»

This README is structured for easy navigation, with interactive collapsible sections to make data analysis smoother. ğŸš€